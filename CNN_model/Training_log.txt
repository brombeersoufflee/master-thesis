Loading data...
Splitting data
Loading train and test indeces...
Splitting train and test data ...
Train data shape: (882, 64, 128, 64), Train labels shape: (882,)
Test data shape: (228, 64, 128, 64), Test labels shape: (228,)
[[ True False]
 [ True False]
 [ True False]
 ...
 [ True False]
 [ True False]
 [ True False]]
5-Fold split created

Model: "functional"

┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)        │ (None, 64, 128, 64, 1) │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv3d (Conv3D)                 │ (None, 32, 64, 32, 64) │        22,016 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization             │ (None, 32, 64, 32, 64) │           256 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation (Activation)         │ (None, 32, 64, 32, 64) │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv3d_1 (Conv3D)               │ (None, 32, 64, 32, 32) │       256,032 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_1           │ (None, 32, 64, 32, 32) │           128 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_1 (Activation)       │ (None, 32, 64, 32, 32) │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv3d_2 (Conv3D)               │ (None, 32, 64, 32, 32) │        27,680 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_2           │ (None, 32, 64, 32, 32) │           128 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_2 (Activation)       │ (None, 32, 64, 32, 32) │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv3d_3 (Conv3D)               │ (None, 32, 64, 32, 32) │        27,680 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_3           │ (None, 32, 64, 32, 32) │           128 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_3 (Activation)       │ (None, 32, 64, 32, 32) │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv3d_4 (Conv3D)               │ (None, 32, 64, 32, 32) │        27,680 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_4           │ (None, 32, 64, 32, 32) │           128 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_4 (Activation)       │ (None, 32, 64, 32, 32) │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_average_pooling3d        │ (None, 32)             │             0 │
│ (GlobalAveragePooling3D)        │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 2)              │            66 │
└─────────────────────────────────┴────────────────────────┴───────────────┘

 Total params: 361,922 (1.38 MB)

 Trainable params: 361,538 (1.38 MB)

 Non-trainable params: 384 (1.50 KB)

None
Fold 1/5
Xtrains shape (706, 64, 128, 64, 1)
Xvals shape (176, 64, 128, 64, 1)
Epoch 1/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 138s 2s/step - accuracy: 0.7535 - auc: 0.8270 - loss: 0.5305 - val_accuracy: 0.1705 - val_auc: 0.1705 - val_loss: 18.3059
Epoch 2/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 39s 1s/step - accuracy: 0.7807 - auc: 0.8577 - loss: 0.4805 - val_accuracy: 0.1705 - val_auc: 0.1705 - val_loss: 12.2033
Epoch 3/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8372 - auc: 0.9015 - loss: 0.4264 - val_accuracy: 0.1705 - val_auc: 0.1705 - val_loss: 9.6618
Epoch 4/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8465 - auc: 0.9246 - loss: 0.3914 - val_accuracy: 0.1705 - val_auc: 0.1705 - val_loss: 12.3499
Epoch 5/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.8407 - auc: 0.9216 - loss: 0.3850 - val_accuracy: 0.1705 - val_auc: 0.1782 - val_loss: 5.9839
Epoch 6/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8708 - auc: 0.9359 - loss: 0.3540 - val_accuracy: 0.1705 - val_auc: 0.2309 - val_loss: 3.5574
Epoch 7/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8722 - auc: 0.9465 - loss: 0.3326 - val_accuracy: 0.1989 - val_auc: 0.2340 - val_loss: 2.0741
Epoch 8/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8719 - auc: 0.9491 - loss: 0.3348 - val_accuracy: 0.8125 - val_auc: 0.9174 - val_loss: 0.3755
Epoch 9/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8765 - auc: 0.9549 - loss: 0.3161 - val_accuracy: 0.8295 - val_auc: 0.9342 - val_loss: 0.5058
Epoch 10/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8863 - auc: 0.9466 - loss: 0.3444 - val_accuracy: 0.1705 - val_auc: 0.1705 - val_loss: 9.5536
Epoch 11/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8677 - auc: 0.9486 - loss: 0.3412 - val_accuracy: 0.2386 - val_auc: 0.2740 - val_loss: 1.8604
Epoch 12/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.8612 - auc: 0.9390 - loss: 0.3414 - val_accuracy: 0.7784 - val_auc: 0.8828 - val_loss: 0.5348
Epoch 13/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8791 - auc: 0.9492 - loss: 0.3295 - val_accuracy: 0.8295 - val_auc: 0.8822 - val_loss: 0.9023
Epoch 14/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.8826 - auc: 0.9560 - loss: 0.3061 - val_accuracy: 0.8295 - val_auc: 0.9261 - val_loss: 0.6552
Epoch 15/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8778 - auc: 0.9507 - loss: 0.3278 - val_accuracy: 0.8693 - val_auc: 0.9397 - val_loss: 0.3141
Epoch 16/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.8681 - auc: 0.9429 - loss: 0.3353 - val_accuracy: 0.8523 - val_auc: 0.9366 - val_loss: 0.3412
Epoch 17/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.9055 - auc: 0.9619 - loss: 0.2859 - val_accuracy: 0.8295 - val_auc: 0.8295 - val_loss: 1.9668
Epoch 18/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8750 - auc: 0.9494 - loss: 0.3284 - val_accuracy: 0.7955 - val_auc: 0.8819 - val_loss: 0.4723
Epoch 19/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8837 - auc: 0.9606 - loss: 0.3092 - val_accuracy: 0.3523 - val_auc: 0.3673 - val_loss: 1.5140
Epoch 20/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8983 - auc: 0.9654 - loss: 0.2897 - val_accuracy: 0.8466 - val_auc: 0.9128 - val_loss: 0.3858
Epoch 21/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.8648 - auc: 0.9477 - loss: 0.3169 - val_accuracy: 0.8409 - val_auc: 0.9406 - val_loss: 0.3197
Epoch 22/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8992 - auc: 0.9679 - loss: 0.2771 - val_accuracy: 0.8523 - val_auc: 0.9454 - val_loss: 0.3545
Epoch 23/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.8973 - auc: 0.9668 - loss: 0.2855 - val_accuracy: 0.8295 - val_auc: 0.9374 - val_loss: 0.4001
Epoch 24/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8803 - auc: 0.9556 - loss: 0.2972 - val_accuracy: 0.8068 - val_auc: 0.9097 - val_loss: 0.3795
Epoch 25/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.9008 - auc: 0.9615 - loss: 0.2924 - val_accuracy: 0.8295 - val_auc: 0.9283 - val_loss: 0.6148
Epoch 26/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8757 - auc: 0.9595 - loss: 0.2883 - val_accuracy: 0.8295 - val_auc: 0.8437 - val_loss: 1.1300
Epoch 27/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.8924 - auc: 0.9686 - loss: 0.2667 - val_accuracy: 0.8352 - val_auc: 0.9366 - val_loss: 0.3279
Epoch 28/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8875 - auc: 0.9657 - loss: 0.2717 - val_accuracy: 0.8295 - val_auc: 0.9297 - val_loss: 0.6664
Epoch 29/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.8912 - auc: 0.9654 - loss: 0.2784 - val_accuracy: 0.8466 - val_auc: 0.9314 - val_loss: 0.3546
Epoch 30/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8776 - auc: 0.9621 - loss: 0.2826 - val_accuracy: 0.8295 - val_auc: 0.9247 - val_loss: 0.7001
Epoch 31/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8799 - auc: 0.9658 - loss: 0.2743 - val_accuracy: 0.8466 - val_auc: 0.9264 - val_loss: 0.3939
Epoch 32/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.8969 - auc: 0.9669 - loss: 0.2641 - val_accuracy: 0.8409 - val_auc: 0.9421 - val_loss: 0.3550
6/6 ━━━━━━━━━━━━━━━━━━━━ 3s 360ms/step
Test AUC: 0.8963

Model: "functional"

┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)        │ (None, 64, 128, 64, 1) │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv3d (Conv3D)                 │ (None, 32, 64, 32, 64) │        22,016 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization             │ (None, 32, 64, 32, 64) │           256 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation (Activation)         │ (None, 32, 64, 32, 64) │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv3d_1 (Conv3D)               │ (None, 32, 64, 32, 32) │       256,032 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_1           │ (None, 32, 64, 32, 32) │           128 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_1 (Activation)       │ (None, 32, 64, 32, 32) │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv3d_2 (Conv3D)               │ (None, 32, 64, 32, 32) │        27,680 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_2           │ (None, 32, 64, 32, 32) │           128 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_2 (Activation)       │ (None, 32, 64, 32, 32) │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv3d_3 (Conv3D)               │ (None, 32, 64, 32, 32) │        27,680 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_3           │ (None, 32, 64, 32, 32) │           128 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_3 (Activation)       │ (None, 32, 64, 32, 32) │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv3d_4 (Conv3D)               │ (None, 32, 64, 32, 32) │        27,680 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_4           │ (None, 32, 64, 32, 32) │           128 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_4 (Activation)       │ (None, 32, 64, 32, 32) │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_average_pooling3d        │ (None, 32)             │             0 │
│ (GlobalAveragePooling3D)        │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 2)              │            66 │
└─────────────────────────────────┴────────────────────────┴───────────────┘

 Total params: 361,922 (1.38 MB)

 Trainable params: 361,538 (1.38 MB)

 Non-trainable params: 384 (1.50 KB)

None
Fold 2/5
Xtrains shape (705, 64, 128, 64, 1)
Xvals shape (177, 64, 128, 64, 1)
Epoch 1/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 52s 2s/step - accuracy: 0.7909 - auc: 0.8327 - loss: 0.5208 - val_accuracy: 0.2599 - val_auc: 0.2599 - val_loss: 4.8866
Epoch 2/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 65s 1s/step - accuracy: 0.8062 - auc: 0.8870 - loss: 0.4574 - val_accuracy: 0.2599 - val_auc: 0.2599 - val_loss: 5.0108
Epoch 3/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.8321 - auc: 0.9048 - loss: 0.4295 - val_accuracy: 0.2599 - val_auc: 0.3311 - val_loss: 4.0601
Epoch 4/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8404 - auc: 0.9220 - loss: 0.3962 - val_accuracy: 0.2599 - val_auc: 0.2599 - val_loss: 10.7514
Epoch 5/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8330 - auc: 0.9289 - loss: 0.3993 - val_accuracy: 0.2599 - val_auc: 0.3449 - val_loss: 3.9927
Epoch 6/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8674 - auc: 0.9349 - loss: 0.3682 - val_accuracy: 0.3051 - val_auc: 0.4145 - val_loss: 0.9655
Epoch 7/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 29s 1s/step - accuracy: 0.8771 - auc: 0.9519 - loss: 0.3361 - val_accuracy: 0.2768 - val_auc: 0.3765 - val_loss: 1.7303
Epoch 8/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 30s 1s/step - accuracy: 0.8611 - auc: 0.9345 - loss: 0.3603 - val_accuracy: 0.7627 - val_auc: 0.8892 - val_loss: 0.4659
Epoch 9/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8580 - auc: 0.9424 - loss: 0.3423 - val_accuracy: 0.3898 - val_auc: 0.4645 - val_loss: 0.9289
Epoch 10/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 30s 1s/step - accuracy: 0.8787 - auc: 0.9501 - loss: 0.3315 - val_accuracy: 0.7458 - val_auc: 0.8796 - val_loss: 0.5142
Epoch 11/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.8745 - auc: 0.9518 - loss: 0.3266 - val_accuracy: 0.4576 - val_auc: 0.5258 - val_loss: 0.8545
Epoch 12/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8601 - auc: 0.9444 - loss: 0.3341 - val_accuracy: 0.7401 - val_auc: 0.8266 - val_loss: 1.3734
Epoch 13/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8718 - auc: 0.9451 - loss: 0.3322 - val_accuracy: 0.7966 - val_auc: 0.8960 - val_loss: 0.4157
Epoch 14/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8893 - auc: 0.9564 - loss: 0.3236 - val_accuracy: 0.8757 - val_auc: 0.9413 - val_loss: 0.3756
Epoch 15/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 30s 1s/step - accuracy: 0.8861 - auc: 0.9627 - loss: 0.2976 - val_accuracy: 0.8023 - val_auc: 0.8855 - val_loss: 0.4415
Epoch 16/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.8996 - auc: 0.9694 - loss: 0.2834 - val_accuracy: 0.7401 - val_auc: 0.8909 - val_loss: 0.5532
Epoch 17/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 30s 1s/step - accuracy: 0.8860 - auc: 0.9503 - loss: 0.3171 - val_accuracy: 0.7458 - val_auc: 0.8954 - val_loss: 0.5387
Epoch 18/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.8929 - auc: 0.9593 - loss: 0.3190 - val_accuracy: 0.4915 - val_auc: 0.5183 - val_loss: 0.8748
Epoch 19/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8575 - auc: 0.9562 - loss: 0.3062 - val_accuracy: 0.2881 - val_auc: 0.4115 - val_loss: 1.6924
Epoch 20/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8840 - auc: 0.9608 - loss: 0.2943 - val_accuracy: 0.2994 - val_auc: 0.4174 - val_loss: 1.3940
Epoch 21/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 30s 1s/step - accuracy: 0.8830 - auc: 0.9593 - loss: 0.2986 - val_accuracy: 0.8418 - val_auc: 0.9218 - val_loss: 0.3561
Epoch 22/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 30s 1s/step - accuracy: 0.8748 - auc: 0.9540 - loss: 0.3082 - val_accuracy: 0.8362 - val_auc: 0.9247 - val_loss: 0.3939
Epoch 23/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8797 - auc: 0.9614 - loss: 0.2854 - val_accuracy: 0.8757 - val_auc: 0.9452 - val_loss: 0.3353
Epoch 24/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8913 - auc: 0.9616 - loss: 0.2886 - val_accuracy: 0.6328 - val_auc: 0.7092 - val_loss: 0.6695
Epoch 25/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.8853 - auc: 0.9619 - loss: 0.2868 - val_accuracy: 0.7345 - val_auc: 0.8609 - val_loss: 0.4664
Epoch 26/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8865 - auc: 0.9611 - loss: 0.2922 - val_accuracy: 0.8701 - val_auc: 0.9397 - val_loss: 0.3333
Epoch 27/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 30s 1s/step - accuracy: 0.9014 - auc: 0.9734 - loss: 0.2695 - val_accuracy: 0.8531 - val_auc: 0.9187 - val_loss: 0.3750
Epoch 28/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.8842 - auc: 0.9545 - loss: 0.3060 - val_accuracy: 0.8192 - val_auc: 0.8972 - val_loss: 0.4113
Epoch 29/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8897 - auc: 0.9651 - loss: 0.2747 - val_accuracy: 0.8588 - val_auc: 0.9401 - val_loss: 0.3570
Epoch 30/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 29s 1s/step - accuracy: 0.8937 - auc: 0.9665 - loss: 0.2689 - val_accuracy: 0.7458 - val_auc: 0.8977 - val_loss: 0.6187
Epoch 31/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.9010 - auc: 0.9689 - loss: 0.2805 - val_accuracy: 0.7401 - val_auc: 0.8942 - val_loss: 0.9299
Epoch 32/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 30s 1s/step - accuracy: 0.9036 - auc: 0.9695 - loss: 0.2650 - val_accuracy: 0.7401 - val_auc: 0.8772 - val_loss: 1.1750
Epoch 33/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 29s 1s/step - accuracy: 0.8979 - auc: 0.9561 - loss: 0.2988 - val_accuracy: 0.8249 - val_auc: 0.9050 - val_loss: 0.4107
6/6 ━━━━━━━━━━━━━━━━━━━━ 3s 404ms/step
Test AUC: 0.9235

Model: "functional"

┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)        │ (None, 64, 128, 64, 1) │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv3d (Conv3D)                 │ (None, 32, 64, 32, 64) │        22,016 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization             │ (None, 32, 64, 32, 64) │           256 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation (Activation)         │ (None, 32, 64, 32, 64) │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv3d_1 (Conv3D)               │ (None, 32, 64, 32, 32) │       256,032 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_1           │ (None, 32, 64, 32, 32) │           128 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_1 (Activation)       │ (None, 32, 64, 32, 32) │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv3d_2 (Conv3D)               │ (None, 32, 64, 32, 32) │        27,680 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_2           │ (None, 32, 64, 32, 32) │           128 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_2 (Activation)       │ (None, 32, 64, 32, 32) │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv3d_3 (Conv3D)               │ (None, 32, 64, 32, 32) │        27,680 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_3           │ (None, 32, 64, 32, 32) │           128 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_3 (Activation)       │ (None, 32, 64, 32, 32) │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv3d_4 (Conv3D)               │ (None, 32, 64, 32, 32) │        27,680 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_4           │ (None, 32, 64, 32, 32) │           128 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_4 (Activation)       │ (None, 32, 64, 32, 32) │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_average_pooling3d        │ (None, 32)             │             0 │
│ (GlobalAveragePooling3D)        │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 2)              │            66 │
└─────────────────────────────────┴────────────────────────┴───────────────┘

 Total params: 361,922 (1.38 MB)

 Trainable params: 361,538 (1.38 MB)

 Non-trainable params: 384 (1.50 KB)

None
Fold 3/5
Xtrains shape (705, 64, 128, 64, 1)
Xvals shape (177, 64, 128, 64, 1)
Epoch 1/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 42s 2s/step - accuracy: 0.2567 - auc: 0.2984 - loss: 0.9399 - val_accuracy: 0.2599 - val_auc: 0.2599 - val_loss: 5.9245
Epoch 2/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 33s 1s/step - accuracy: 0.6661 - auc: 0.7036 - loss: 0.6499 - val_accuracy: 0.2599 - val_auc: 0.2792 - val_loss: 4.5821
Epoch 3/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 29s 1s/step - accuracy: 0.7690 - auc: 0.8288 - loss: 0.5852 - val_accuracy: 0.2599 - val_auc: 0.3635 - val_loss: 2.4301
Epoch 4/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 29s 1s/step - accuracy: 0.7847 - auc: 0.8559 - loss: 0.5519 - val_accuracy: 0.2599 - val_auc: 0.3640 - val_loss: 1.5275
Epoch 5/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 29s 1s/step - accuracy: 0.7437 - auc: 0.8362 - loss: 0.5519 - val_accuracy: 0.2599 - val_auc: 0.3749 - val_loss: 1.2995
Epoch 6/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.7657 - auc: 0.8455 - loss: 0.5401 - val_accuracy: 0.4068 - val_auc: 0.4337 - val_loss: 0.7654
Epoch 7/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 30s 1s/step - accuracy: 0.8015 - auc: 0.8791 - loss: 0.5033 - val_accuracy: 0.5706 - val_auc: 0.6084 - val_loss: 0.6735
Epoch 8/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 30s 1s/step - accuracy: 0.7855 - auc: 0.8725 - loss: 0.4993 - val_accuracy: 0.2599 - val_auc: 0.3381 - val_loss: 3.6956
Epoch 9/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.7807 - auc: 0.8558 - loss: 0.5371 - val_accuracy: 0.2768 - val_auc: 0.3806 - val_loss: 1.5143
Epoch 10/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8226 - auc: 0.8960 - loss: 0.4835 - val_accuracy: 0.3503 - val_auc: 0.4113 - val_loss: 0.9929
Epoch 11/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8134 - auc: 0.8992 - loss: 0.4667 - val_accuracy: 0.4576 - val_auc: 0.4908 - val_loss: 0.8069
Epoch 12/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 30s 1s/step - accuracy: 0.8038 - auc: 0.8849 - loss: 0.4751 - val_accuracy: 0.8023 - val_auc: 0.8928 - val_loss: 0.5234
Epoch 13/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 30s 1s/step - accuracy: 0.8200 - auc: 0.8983 - loss: 0.4505 - val_accuracy: 0.8023 - val_auc: 0.8900 - val_loss: 0.5215
Epoch 14/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.8420 - auc: 0.9219 - loss: 0.4252 - val_accuracy: 0.2599 - val_auc: 0.3729 - val_loss: 2.1038
Epoch 15/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8400 - auc: 0.9109 - loss: 0.4572 - val_accuracy: 0.4520 - val_auc: 0.4739 - val_loss: 0.8189
Epoch 16/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 29s 1s/step - accuracy: 0.8339 - auc: 0.9175 - loss: 0.4361 - val_accuracy: 0.8305 - val_auc: 0.9076 - val_loss: 0.4692
Epoch 17/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8496 - auc: 0.9323 - loss: 0.4030 - val_accuracy: 0.6102 - val_auc: 0.6215 - val_loss: 0.6909
Epoch 18/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 30s 1s/step - accuracy: 0.8446 - auc: 0.9291 - loss: 0.4099 - val_accuracy: 0.7345 - val_auc: 0.8166 - val_loss: 0.5533
Epoch 19/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 29s 1s/step - accuracy: 0.8624 - auc: 0.9357 - loss: 0.3953 - val_accuracy: 0.8588 - val_auc: 0.9320 - val_loss: 0.4403
Epoch 20/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8618 - auc: 0.9408 - loss: 0.3860 - val_accuracy: 0.8531 - val_auc: 0.9296 - val_loss: 0.4148
Epoch 21/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.8591 - auc: 0.9404 - loss: 0.3795 - val_accuracy: 0.2768 - val_auc: 0.3920 - val_loss: 1.8484
Epoch 22/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8367 - auc: 0.9346 - loss: 0.3907 - val_accuracy: 0.8192 - val_auc: 0.9227 - val_loss: 0.4147
Epoch 23/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8715 - auc: 0.9382 - loss: 0.3804 - val_accuracy: 0.2599 - val_auc: 0.3921 - val_loss: 1.9253
Epoch 24/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.8604 - auc: 0.9368 - loss: 0.4007 - val_accuracy: 0.8531 - val_auc: 0.9452 - val_loss: 0.3572
Epoch 25/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 29s 1s/step - accuracy: 0.8734 - auc: 0.9509 - loss: 0.3622 - val_accuracy: 0.2599 - val_auc: 0.3698 - val_loss: 3.3073
Epoch 26/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8448 - auc: 0.9374 - loss: 0.3826 - val_accuracy: 0.2599 - val_auc: 0.2614 - val_loss: 7.8522
Epoch 27/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8807 - auc: 0.9523 - loss: 0.3610 - val_accuracy: 0.2655 - val_auc: 0.3604 - val_loss: 3.2164
Epoch 28/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.8523 - auc: 0.9337 - loss: 0.3862 - val_accuracy: 0.2599 - val_auc: 0.3735 - val_loss: 3.3924
Epoch 29/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8658 - auc: 0.9416 - loss: 0.3624 - val_accuracy: 0.2712 - val_auc: 0.4133 - val_loss: 2.0171
Epoch 30/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8563 - auc: 0.9475 - loss: 0.3612 - val_accuracy: 0.2599 - val_auc: 0.3706 - val_loss: 3.1803
Epoch 31/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8517 - auc: 0.9422 - loss: 0.3686 - val_accuracy: 0.8475 - val_auc: 0.9120 - val_loss: 0.4199
Epoch 32/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 29s 1s/step - accuracy: 0.8686 - auc: 0.9476 - loss: 0.3486 - val_accuracy: 0.2599 - val_auc: 0.2760 - val_loss: 6.2237
Epoch 33/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8931 - auc: 0.9537 - loss: 0.3517 - val_accuracy: 0.8531 - val_auc: 0.9458 - val_loss: 0.3156
Epoch 34/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.8726 - auc: 0.9532 - loss: 0.3383 - val_accuracy: 0.7232 - val_auc: 0.7989 - val_loss: 0.5447
Epoch 35/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 29s 1s/step - accuracy: 0.8815 - auc: 0.9589 - loss: 0.3286 - val_accuracy: 0.2599 - val_auc: 0.3349 - val_loss: 4.5457
Epoch 36/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 29s 1s/step - accuracy: 0.8683 - auc: 0.9412 - loss: 0.3612 - val_accuracy: 0.8249 - val_auc: 0.9297 - val_loss: 0.3420
Epoch 37/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8668 - auc: 0.9467 - loss: 0.3441 - val_accuracy: 0.4915 - val_auc: 0.5652 - val_loss: 0.9726
Epoch 38/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 30s 1s/step - accuracy: 0.8680 - auc: 0.9484 - loss: 0.3395 - val_accuracy: 0.8418 - val_auc: 0.9333 - val_loss: 0.3452
Epoch 39/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 29s 1s/step - accuracy: 0.8813 - auc: 0.9563 - loss: 0.3203 - val_accuracy: 0.8701 - val_auc: 0.9453 - val_loss: 0.3683
Epoch 40/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 43s 1s/step - accuracy: 0.8802 - auc: 0.9590 - loss: 0.3196 - val_accuracy: 0.6949 - val_auc: 0.7693 - val_loss: 0.5856
Epoch 41/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.8851 - auc: 0.9592 - loss: 0.3250 - val_accuracy: 0.3333 - val_auc: 0.4248 - val_loss: 1.7472
Epoch 42/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.9022 - auc: 0.9638 - loss: 0.3146 - val_accuracy: 0.8588 - val_auc: 0.9430 - val_loss: 0.3465
Epoch 43/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.8860 - auc: 0.9557 - loss: 0.3205 - val_accuracy: 0.6271 - val_auc: 0.6706 - val_loss: 0.8218

WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7ebb963f6480> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.

6/6 ━━━━━━━━━━━━━━━━━━━━ 3s 403ms/step
Test AUC: 0.9250

Model: "functional"

┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)        │ (None, 64, 128, 64, 1) │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv3d (Conv3D)                 │ (None, 32, 64, 32, 64) │        22,016 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization             │ (None, 32, 64, 32, 64) │           256 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation (Activation)         │ (None, 32, 64, 32, 64) │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv3d_1 (Conv3D)               │ (None, 32, 64, 32, 32) │       256,032 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_1           │ (None, 32, 64, 32, 32) │           128 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_1 (Activation)       │ (None, 32, 64, 32, 32) │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv3d_2 (Conv3D)               │ (None, 32, 64, 32, 32) │        27,680 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_2           │ (None, 32, 64, 32, 32) │           128 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_2 (Activation)       │ (None, 32, 64, 32, 32) │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv3d_3 (Conv3D)               │ (None, 32, 64, 32, 32) │        27,680 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_3           │ (None, 32, 64, 32, 32) │           128 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_3 (Activation)       │ (None, 32, 64, 32, 32) │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv3d_4 (Conv3D)               │ (None, 32, 64, 32, 32) │        27,680 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_4           │ (None, 32, 64, 32, 32) │           128 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_4 (Activation)       │ (None, 32, 64, 32, 32) │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_average_pooling3d        │ (None, 32)             │             0 │
│ (GlobalAveragePooling3D)        │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 2)              │            66 │
└─────────────────────────────────┴────────────────────────┴───────────────┘

 Total params: 361,922 (1.38 MB)

 Trainable params: 361,538 (1.38 MB)

 Non-trainable params: 384 (1.50 KB)

None
Fold 4/5
Xtrains shape (709, 64, 128, 64, 1)
Xvals shape (173, 64, 128, 64, 1)
Epoch 1/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 60s 2s/step - accuracy: 0.7654 - auc: 0.8224 - loss: 0.5880 - val_accuracy: 0.2370 - val_auc: 0.2370 - val_loss: 17.5822
Epoch 2/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 57s 1s/step - accuracy: 0.7976 - auc: 0.8819 - loss: 0.4644 - val_accuracy: 0.2370 - val_auc: 0.2353 - val_loss: 5.2322
Epoch 3/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.8169 - auc: 0.8945 - loss: 0.4298 - val_accuracy: 0.2370 - val_auc: 0.2370 - val_loss: 6.9978
Epoch 4/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.7997 - auc: 0.8842 - loss: 0.4412 - val_accuracy: 0.2370 - val_auc: 0.3527 - val_loss: 2.5091
Epoch 5/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8510 - auc: 0.9110 - loss: 0.4038 - val_accuracy: 0.2370 - val_auc: 0.2566 - val_loss: 5.1335
Epoch 6/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8555 - auc: 0.9217 - loss: 0.3862 - val_accuracy: 0.2370 - val_auc: 0.2941 - val_loss: 4.6907
Epoch 7/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.8544 - auc: 0.9364 - loss: 0.3548 - val_accuracy: 0.2370 - val_auc: 0.2540 - val_loss: 5.4432
Epoch 8/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8618 - auc: 0.9372 - loss: 0.3550 - val_accuracy: 0.2890 - val_auc: 0.3858 - val_loss: 1.5519
Epoch 9/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8598 - auc: 0.9423 - loss: 0.3440 - val_accuracy: 0.2370 - val_auc: 0.2436 - val_loss: 5.8061
Epoch 10/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 30s 1s/step - accuracy: 0.8516 - auc: 0.9391 - loss: 0.3574 - val_accuracy: 0.7630 - val_auc: 0.9023 - val_loss: 0.4947
Epoch 11/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8816 - auc: 0.9557 - loss: 0.3136 - val_accuracy: 0.7630 - val_auc: 0.9067 - val_loss: 0.5686
Epoch 12/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 30s 1s/step - accuracy: 0.8560 - auc: 0.9376 - loss: 0.3527 - val_accuracy: 0.5838 - val_auc: 0.6394 - val_loss: 0.7437
Epoch 13/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.8775 - auc: 0.9505 - loss: 0.3164 - val_accuracy: 0.7457 - val_auc: 0.8227 - val_loss: 0.5190
Epoch 14/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8791 - auc: 0.9457 - loss: 0.3258 - val_accuracy: 0.8613 - val_auc: 0.9397 - val_loss: 0.3141
Epoch 15/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 29s 1s/step - accuracy: 0.8752 - auc: 0.9463 - loss: 0.3258 - val_accuracy: 0.6647 - val_auc: 0.7495 - val_loss: 0.6731
Epoch 16/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 29s 1s/step - accuracy: 0.8796 - auc: 0.9567 - loss: 0.3001 - val_accuracy: 0.2370 - val_auc: 0.2728 - val_loss: 5.2612
Epoch 17/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8865 - auc: 0.9558 - loss: 0.3086 - val_accuracy: 0.8671 - val_auc: 0.9284 - val_loss: 0.3751
Epoch 18/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8970 - auc: 0.9599 - loss: 0.2952 - val_accuracy: 0.8208 - val_auc: 0.8973 - val_loss: 0.4454
Epoch 19/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 30s 1s/step - accuracy: 0.8745 - auc: 0.9542 - loss: 0.3020 - val_accuracy: 0.8902 - val_auc: 0.9607 - val_loss: 0.2827
Epoch 20/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.9015 - auc: 0.9637 - loss: 0.2843 - val_accuracy: 0.6474 - val_auc: 0.7199 - val_loss: 0.6366
Epoch 21/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8940 - auc: 0.9592 - loss: 0.2880 - val_accuracy: 0.4798 - val_auc: 0.4978 - val_loss: 1.5824
Epoch 22/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.8834 - auc: 0.9600 - loss: 0.2900 - val_accuracy: 0.7630 - val_auc: 0.9182 - val_loss: 0.5685
Epoch 23/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8668 - auc: 0.9539 - loss: 0.3117 - val_accuracy: 0.7630 - val_auc: 0.8701 - val_loss: 0.6124
Epoch 24/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8799 - auc: 0.9536 - loss: 0.2975 - val_accuracy: 0.8844 - val_auc: 0.9477 - val_loss: 0.2982
Epoch 25/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 30s 1s/step - accuracy: 0.8744 - auc: 0.9513 - loss: 0.3010 - val_accuracy: 0.9017 - val_auc: 0.9602 - val_loss: 0.2842
Epoch 26/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.8999 - auc: 0.9632 - loss: 0.2840 - val_accuracy: 0.7630 - val_auc: 0.8209 - val_loss: 1.4235
Epoch 27/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8714 - auc: 0.9531 - loss: 0.3042 - val_accuracy: 0.8555 - val_auc: 0.9176 - val_loss: 0.3671
Epoch 28/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 29s 1s/step - accuracy: 0.9032 - auc: 0.9669 - loss: 0.2699 - val_accuracy: 0.7688 - val_auc: 0.9216 - val_loss: 0.5120
Epoch 29/100
23/23 ━━━━━━━━━━━━━━━━━━━━ 29s 1s/step - accuracy: 0.8904 - auc: 0.9572 - loss: 0.2922 - val_accuracy: 0.8324 - val_auc: 0.9312 - val_loss: 0.3431

WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7ebb91951120> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.

6/6 ━━━━━━━━━━━━━━━━━━━━ 3s 357ms/step
Test AUC: 0.9451

Model: "functional"

┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)        │ (None, 64, 128, 64, 1) │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv3d (Conv3D)                 │ (None, 32, 64, 32, 64) │        22,016 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization             │ (None, 32, 64, 32, 64) │           256 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation (Activation)         │ (None, 32, 64, 32, 64) │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv3d_1 (Conv3D)               │ (None, 32, 64, 32, 32) │       256,032 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_1           │ (None, 32, 64, 32, 32) │           128 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_1 (Activation)       │ (None, 32, 64, 32, 32) │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv3d_2 (Conv3D)               │ (None, 32, 64, 32, 32) │        27,680 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_2           │ (None, 32, 64, 32, 32) │           128 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_2 (Activation)       │ (None, 32, 64, 32, 32) │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv3d_3 (Conv3D)               │ (None, 32, 64, 32, 32) │        27,680 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_3           │ (None, 32, 64, 32, 32) │           128 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_3 (Activation)       │ (None, 32, 64, 32, 32) │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv3d_4 (Conv3D)               │ (None, 32, 64, 32, 32) │        27,680 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_4           │ (None, 32, 64, 32, 32) │           128 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_4 (Activation)       │ (None, 32, 64, 32, 32) │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ global_average_pooling3d        │ (None, 32)             │             0 │
│ (GlobalAveragePooling3D)        │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 2)              │            66 │
└─────────────────────────────────┴────────────────────────┴───────────────┘

 Total params: 361,922 (1.38 MB)

 Trainable params: 361,538 (1.38 MB)

 Non-trainable params: 384 (1.50 KB)

None
Fold 5/5
Xtrains shape (703, 64, 128, 64, 1)
Xvals shape (179, 64, 128, 64, 1)
Epoch 1/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 128s 6s/step - accuracy: 0.7689 - auc: 0.8381 - loss: 0.5479 - val_accuracy: 0.2291 - val_auc: 0.2291 - val_loss: 7.4524
Epoch 2/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 50s 1s/step - accuracy: 0.7964 - auc: 0.8884 - loss: 0.4628 - val_accuracy: 0.2291 - val_auc: 0.2291 - val_loss: 12.5972
Epoch 3/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 39s 1s/step - accuracy: 0.8081 - auc: 0.8879 - loss: 0.4397 - val_accuracy: 0.2291 - val_auc: 0.2291 - val_loss: 7.3258
Epoch 4/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 29s 1s/step - accuracy: 0.8259 - auc: 0.9055 - loss: 0.4119 - val_accuracy: 0.2291 - val_auc: 0.2291 - val_loss: 8.1259
Epoch 5/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8480 - auc: 0.9250 - loss: 0.3801 - val_accuracy: 0.2291 - val_auc: 0.2291 - val_loss: 8.1154
Epoch 6/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 30s 1s/step - accuracy: 0.8537 - auc: 0.9367 - loss: 0.3609 - val_accuracy: 0.2291 - val_auc: 0.2367 - val_loss: 5.4605
Epoch 7/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8400 - auc: 0.9178 - loss: 0.3864 - val_accuracy: 0.2291 - val_auc: 0.2913 - val_loss: 4.2772
Epoch 8/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8353 - auc: 0.9259 - loss: 0.3676 - val_accuracy: 0.8101 - val_auc: 0.8817 - val_loss: 0.4650
Epoch 9/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.8524 - auc: 0.9283 - loss: 0.3639 - val_accuracy: 0.4525 - val_auc: 0.4528 - val_loss: 1.0506
Epoch 10/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 29s 1s/step - accuracy: 0.8564 - auc: 0.9450 - loss: 0.3334 - val_accuracy: 0.3240 - val_auc: 0.3560 - val_loss: 1.6397
Epoch 11/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8867 - auc: 0.9527 - loss: 0.3182 - val_accuracy: 0.5475 - val_auc: 0.5590 - val_loss: 0.9325
Epoch 12/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8729 - auc: 0.9435 - loss: 0.3300 - val_accuracy: 0.7989 - val_auc: 0.8751 - val_loss: 0.4415
Epoch 13/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 30s 1s/step - accuracy: 0.8873 - auc: 0.9588 - loss: 0.2997 - val_accuracy: 0.8324 - val_auc: 0.9180 - val_loss: 0.3722
Epoch 14/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8966 - auc: 0.9661 - loss: 0.2894 - val_accuracy: 0.4413 - val_auc: 0.4698 - val_loss: 1.2653
Epoch 15/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8957 - auc: 0.9606 - loss: 0.2934 - val_accuracy: 0.8324 - val_auc: 0.9035 - val_loss: 0.4038
Epoch 16/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.8985 - auc: 0.9589 - loss: 0.2936 - val_accuracy: 0.8436 - val_auc: 0.9281 - val_loss: 0.3633
Epoch 17/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8753 - auc: 0.9524 - loss: 0.3078 - val_accuracy: 0.7821 - val_auc: 0.8967 - val_loss: 0.7058
Epoch 18/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.8455 - auc: 0.9371 - loss: 0.3374 - val_accuracy: 0.7765 - val_auc: 0.9098 - val_loss: 0.5782
Epoch 19/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8833 - auc: 0.9522 - loss: 0.3041 - val_accuracy: 0.8436 - val_auc: 0.9381 - val_loss: 0.3192
Epoch 20/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8698 - auc: 0.9544 - loss: 0.2979 - val_accuracy: 0.8156 - val_auc: 0.9159 - val_loss: 0.3849
Epoch 21/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8885 - auc: 0.9544 - loss: 0.2981 - val_accuracy: 0.8212 - val_auc: 0.9139 - val_loss: 0.3796
Epoch 22/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.8837 - auc: 0.9575 - loss: 0.2896 - val_accuracy: 0.8045 - val_auc: 0.8796 - val_loss: 0.4333
Epoch 23/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8969 - auc: 0.9600 - loss: 0.2830 - val_accuracy: 0.5251 - val_auc: 0.5554 - val_loss: 1.1367
Epoch 24/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 30s 1s/step - accuracy: 0.8933 - auc: 0.9667 - loss: 0.2730 - val_accuracy: 0.2291 - val_auc: 0.2521 - val_loss: 5.8949
Epoch 25/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.8973 - auc: 0.9651 - loss: 0.2804 - val_accuracy: 0.8547 - val_auc: 0.9270 - val_loss: 0.3695
Epoch 26/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8989 - auc: 0.9695 - loss: 0.2669 - val_accuracy: 0.8492 - val_auc: 0.9440 - val_loss: 0.3455
Epoch 27/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.9113 - auc: 0.9655 - loss: 0.2719 - val_accuracy: 0.8101 - val_auc: 0.8504 - val_loss: 0.4803
Epoch 28/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 29s 1s/step - accuracy: 0.9037 - auc: 0.9669 - loss: 0.2641 - val_accuracy: 0.7877 - val_auc: 0.8391 - val_loss: 0.5027
Epoch 29/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8974 - auc: 0.9647 - loss: 0.2667 - val_accuracy: 0.2291 - val_auc: 0.3445 - val_loss: 2.9290
Epoch 30/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 30s 1s/step - accuracy: 0.9180 - auc: 0.9753 - loss: 0.2504 - val_accuracy: 0.8659 - val_auc: 0.9451 - val_loss: 0.3042
Epoch 31/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 29s 1s/step - accuracy: 0.9131 - auc: 0.9705 - loss: 0.2609 - val_accuracy: 0.8492 - val_auc: 0.9314 - val_loss: 0.3525
Epoch 32/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8981 - auc: 0.9728 - loss: 0.2452 - val_accuracy: 0.8380 - val_auc: 0.9288 - val_loss: 0.4068
Epoch 33/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.9133 - auc: 0.9741 - loss: 0.2438 - val_accuracy: 0.8659 - val_auc: 0.9518 - val_loss: 0.2924
Epoch 34/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.9128 - auc: 0.9755 - loss: 0.2405 - val_accuracy: 0.6536 - val_auc: 0.7499 - val_loss: 0.5950
Epoch 35/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8910 - auc: 0.9638 - loss: 0.2654 - val_accuracy: 0.7989 - val_auc: 0.8771 - val_loss: 0.4467
Epoch 36/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.9244 - auc: 0.9765 - loss: 0.2312 - val_accuracy: 0.8436 - val_auc: 0.9343 - val_loss: 0.3342
Epoch 37/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.9188 - auc: 0.9775 - loss: 0.2335 - val_accuracy: 0.7709 - val_auc: 0.8575 - val_loss: 0.4805
Epoch 38/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 29s 1s/step - accuracy: 0.9080 - auc: 0.9725 - loss: 0.2474 - val_accuracy: 0.6089 - val_auc: 0.6702 - val_loss: 0.8421
Epoch 39/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8972 - auc: 0.9693 - loss: 0.2549 - val_accuracy: 0.8156 - val_auc: 0.9264 - val_loss: 0.4097
Epoch 40/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.8795 - auc: 0.9649 - loss: 0.2593 - val_accuracy: 0.8436 - val_auc: 0.9368 - val_loss: 0.3475
Epoch 41/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8981 - auc: 0.9622 - loss: 0.2643 - val_accuracy: 0.8156 - val_auc: 0.9234 - val_loss: 0.4477
Epoch 42/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8933 - auc: 0.9720 - loss: 0.2401 - val_accuracy: 0.8324 - val_auc: 0.9159 - val_loss: 0.3688
Epoch 43/100
22/22 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.9246 - auc: 0.9779 - loss: 0.2255 - val_accuracy: 0.8659 - val_auc: 0.9416 - val_loss: 0.3268
6/6 ━━━━━━━━━━━━━━━━━━━━ 3s 365ms/step
Test AUC: 0.9259
